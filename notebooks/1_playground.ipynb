{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_video(input_file, output_file):\n",
    "    try:\n",
    "        (\n",
    "            ffmpeg\n",
    "            .input(input_file)\n",
    "            .output(output_file,\n",
    "                    vcodec='libx264',\n",
    "                    crf=23,\n",
    "                    vprofile='baseline',\n",
    "                    level='3.0',\n",
    "                    pix_fmt='yuv420p',\n",
    "                    acodec='aac',\n",
    "                    ac=2,\n",
    "                    audio_bitrate='128k',\n",
    "                    movflags='faststart',\n",
    "                    )\n",
    "            .overwrite_output()\n",
    "            .run()\n",
    "        )\n",
    "        print(f\"Conversion successful: {output_file}\")\n",
    "    except ffmpeg.Error as e:\n",
    "        print(f\"Error during conversion: {e.stderr.decode()}\")\n",
    "\n",
    "def preprocess_audio(input_file, output_file):\n",
    "    try:\n",
    "        (\n",
    "            ffmpeg\n",
    "            .input(input_file)\n",
    "            .output(output_file,\n",
    "                    # vn=True,  # Disable video stream\n",
    "                    acodec='pcm_s16le',\n",
    "                    ar=44100,\n",
    "                    )\n",
    "            .overwrite_output()\n",
    "            .run()\n",
    "        )\n",
    "        print(f\"Audio extraction successful: {output_file}\")\n",
    "    except ffmpeg.Error as e:\n",
    "        print(f\"Error during audio extraction: \", e)\n",
    "\n",
    "# Example usage\n",
    "# preprocess_video('../data/HY_2024_film_01.mp4', '../data_processed/output.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/szymon/repos/hy_ai/notebooks/../data/HY_2024_film_01.mp4'),\n",
       " PosixPath('/home/szymon/repos/hy_ai/notebooks/../data/HY_2024_film_02.mp4'),\n",
       " PosixPath('/home/szymon/repos/hy_ai/notebooks/../data/HY_2024_film_03.mp4'),\n",
       " PosixPath('/home/szymon/repos/hy_ai/notebooks/../data/HY_2024_film_04.mp4'),\n",
       " PosixPath('/home/szymon/repos/hy_ai/notebooks/../data/HY_2024_film_05.mp4'),\n",
       " PosixPath('/home/szymon/repos/hy_ai/notebooks/../data/HY_2024_film_06.mp4'),\n",
       " PosixPath('/home/szymon/repos/hy_ai/notebooks/../data/HY_2024_film_07.mp4'),\n",
       " PosixPath('/home/szymon/repos/hy_ai/notebooks/../data/HY_2024_film_08.mp4'),\n",
       " PosixPath('/home/szymon/repos/hy_ai/notebooks/../data/HY_2024_film_09.mp4'),\n",
       " PosixPath('/home/szymon/repos/hy_ai/notebooks/../data/HY_2024_film_10.mp4'),\n",
       " PosixPath('/home/szymon/repos/hy_ai/notebooks/../data/HY_2024_film_11.mp4'),\n",
       " PosixPath('/home/szymon/repos/hy_ai/notebooks/../data/HY_2024_film_12.mp4'),\n",
       " PosixPath('/home/szymon/repos/hy_ai/notebooks/../data/HY_2024_film_13.mp4'),\n",
       " PosixPath('/home/szymon/repos/hy_ai/notebooks/../data/HY_2024_film_14.mp4'),\n",
       " PosixPath('/home/szymon/repos/hy_ai/notebooks/../data/HY_2024_film_15.mp4'),\n",
       " PosixPath('/home/szymon/repos/hy_ai/notebooks/../data/HY_2024_film_16.mp4'),\n",
       " PosixPath('/home/szymon/repos/hy_ai/notebooks/../data/HY_2024_film_17.mp4'),\n",
       " PosixPath('/home/szymon/repos/hy_ai/notebooks/../data/HY_2024_film_18.mp4'),\n",
       " PosixPath('/home/szymon/repos/hy_ai/notebooks/../data/HY_2024_film_19.mp4'),\n",
       " PosixPath('/home/szymon/repos/hy_ai/notebooks/../data/HY_2024_film_20.mp4'),\n",
       " PosixPath('/home/szymon/repos/hy_ai/notebooks/../data/output_audio.aac')]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list all absolute filenames in ../data dir\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "PATH =  Path('../data')\n",
    "TEST_FILENAMES = sorted([Path(PATH / p).absolute() for p in os.listdir(PATH)])\n",
    "TEST_FILENAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio extraction successful: ../data_processed/output.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/home/szymon/repos/hy_ai/notebooks/../data/HY_2024_film_01.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    creation_time   : 2024-09-20T10:27:44.000000Z\n",
      "  Duration: 00:00:32.11, start: 0.000000, bitrate: 20129 kb/s\n",
      "  Stream #0:0(eng): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709), 1920x1080, 19813 kb/s, 25 fps, 25 tbr, 25k tbn, 50k tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-09-20T10:27:44.000000Z\n",
      "      handler_name    : ?Mainconcept Video Media Handler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : AVC Coding\n",
      "  Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 317 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-09-20T10:27:46.000000Z\n",
      "      handler_name    : #Mainconcept MP4 Sound Media Handler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to '../data_processed/output.wav':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42mp41\n",
      "    ISFT            : Lavf58.76.100\n",
      "  Stream #0:0(eng): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2024-09-20T10:27:46.000000Z\n",
      "      handler_name    : #Mainconcept MP4 Sound Media Handler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc58.134.100 pcm_s16le\n",
      "size=    5527kB time=00:00:32.08 bitrate=1411.2kbits/s speed= 528x    \n",
      "video:0kB audio:5527kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.001378%\n"
     ]
    }
   ],
   "source": [
    "AUDIO_FILE = str(TEST_FILENAMES[0])\n",
    "\n",
    "# 1. Preprocess audio\n",
    "preprocess_audio(AUDIO_FILE, \n",
    "                 '../data_processed/output.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Feed recognizer\n",
    "r = sr.Recognizer()\n",
    "with sr.AudioFile(\"../data_processed/output.wav\") as source:\n",
    "    audio = r.record(source)  # read the entire audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2.88G/2.88G [05:02<00:00, 10.2MiB/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 7.75 GiB of which 31.31 MiB is free. Including non-PyTorch memory, this process has 6.11 GiB memory in use. Of the allocated memory 5.64 GiB is allocated by PyTorch, and 320.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[120], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGlossary: wzmożonej, wzmożona, wzmożony, Polska\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 5\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize_whisper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlarge\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43maudio_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpolish\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mword_timestamps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sr\u001b[38;5;241m.\u001b[39mUnknownValueError:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not understand audio\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/repos/hy_ai/hy_ai/lib/python3.10/site-packages/speech_recognition/__init__.py:1412\u001b[0m, in \u001b[0;36mRecognizer.recognize_whisper\u001b[0;34m(self, audio_data, model, show_dict, load_options, language, translate, **transcribe_options)\u001b[0m\n\u001b[1;32m   1410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_options \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhisper_model\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhisper_model\u001b[38;5;241m.\u001b[39mget(model) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1411\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhisper_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhisper_model\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m-> 1412\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhisper_model[model] \u001b[38;5;241m=\u001b[39m \u001b[43mwhisper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mload_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;66;03m# 16 kHz https://github.com/openai/whisper/blob/28769fcfe50755a817ab922a7bc83483159600a9/whisper/audio.py#L98-L99\u001b[39;00m\n\u001b[1;32m   1415\u001b[0m wav_bytes \u001b[38;5;241m=\u001b[39m audio_data\u001b[38;5;241m.\u001b[39mget_wav_data(convert_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16000\u001b[39m)\n",
      "File \u001b[0;32m~/repos/hy_ai/hy_ai/lib/python3.10/site-packages/whisper/__init__.py:156\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, device, download_root, in_memory)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m alignment_heads \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     model\u001b[38;5;241m.\u001b[39mset_alignment_heads(alignment_heads)\n\u001b[0;32m--> 156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/hy_ai/hy_ai/lib/python3.10/site-packages/torch/nn/modules/module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/hy_ai/hy_ai/lib/python3.10/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/hy_ai/hy_ai/lib/python3.10/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 780 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/repos/hy_ai/hy_ai/lib/python3.10/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/hy_ai/hy_ai/lib/python3.10/site-packages/torch/nn/modules/module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/hy_ai/hy_ai/lib/python3.10/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1155\u001b[0m             device,\n\u001b[1;32m   1156\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m             non_blocking,\n\u001b[1;32m   1158\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1159\u001b[0m         )\n\u001b[0;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 7.75 GiB of which 31.31 MiB is free. Including non-PyTorch memory, this process has 6.11 GiB memory in use. Of the allocated memory 5.64 GiB is allocated by PyTorch, and 320.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# 3. Recodnize speech\n",
    "prompt = \"Glossary: wzmożonej, wzmożona, wzmożony, Polska\"\n",
    "\n",
    "try:\n",
    "    output = r.recognize_whisper(\n",
    "        model=\"large\",\n",
    "        audio_data=audio, \n",
    "        language=\"polish\",\n",
    "        word_timestamps=False,\n",
    "        show_dict=False,\n",
    "        prompt=prompt,\n",
    "        )\n",
    "except sr.UnknownValueError:\n",
    "    print(\"could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"error; {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Ałdytem objęliśmy 96 podmiotów, a już na kwota badanej środków publicznych to około 100 miliardów złotych. Wtoku działy stwierdziliśmy między innymi niegospodalne i niecelowe wydatkowanie środków publicznych, udzielenie dotacji podmiotów, które nie spełniały kryteriów konkursowych, które nie spełniały do wydawnia. To już nie spowodowałem, że nie spowodowałem, że nie spowodowałem, że nie spowodowałem, że nie spowodowałem, że nie spowodowałem, że nie spowodowałem, że nie spowodowałem, że nie spowodowałem, że nie spowodowałem, że nie spowodowałem, że nie spowodowałem, że nie spowodowałem, że nie spowodowałem, że nie spowodowałem, że nie spowodowałem, że nie spowodowałem, że nie spowodowałem, że nie spowodowałem, że nie spowodowałem, że nie spowodowałem, że nie spowodowałem, że nie spowodowałem, że nie spowodowałem, że nie spowodowałem, że nie spowodowałem, że nie spowodowałem, że nie spowodowa'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "DATA = {'text': ' W pierwszej połowie lipca przeprowadziliśmy ogólnopolską akcję z możonej kontroli przesyłek pocztowych oraz kurierskich. Funkcjonariusze przeprowadzili kontrolę w 18 punktach w całej Polsce. Wrześniowa zmiana warunków o prezentowanie obligacji oszczędnościowych wynika z potrzeby ich do stosowania do bieżących realiów rynkowych.', 'segments': [{'id': 0, 'seek': 0, 'start': np.float64(11.26), 'end': np.float64(17.84), 'text': ' W pierwszej połowie lipca przeprowadziliśmy ogólnopolską akcję z możonej kontroli przesyłek pocztowych oraz kurierskich.', 'tokens': [50364, 343, 27623, 16920, 714, 1221, 13998, 8280, 496, 30829, 1892, 345, 89, 43912, 5360, 15741, 77, 19946, 5161, 1611, 9308, 41960, 710, 705, 1427, 546, 73, 14373, 340, 2081, 6541, 17823, 1221, 916, 714, 66, 2682, 19605, 28905, 10072, 4890, 48349, 13, 51264], 'temperature': 0.0, 'avg_logprob': -0.1916964572408925, 'compression_ratio': 1.251572327044025, 'no_speech_prob': 0.1463223397731781, 'words': [{'word': ' W', 'start': np.float64(11.26), 'end': np.float64(12.1), 'probability': np.float64(0.5698226094245911)}, {'word': ' pierwszej', 'start': np.float64(12.1), 'end': np.float64(12.38), 'probability': np.float64(0.9487821459770203)}, {'word': ' połowie', 'start': np.float64(12.38), 'end': np.float64(12.68), 'probability': np.float64(0.9906543095906576)}, {'word': ' lipca', 'start': np.float64(12.68), 'end': np.float64(13.06), 'probability': np.float64(0.9368249475955963)}, {'word': ' przeprowadziliśmy', 'start': np.float64(13.06), 'end': np.float64(13.76), 'probability': np.float64(0.9441170692443848)}, {'word': ' ogólnopolską', 'start': np.float64(13.76), 'end': np.float64(14.64), 'probability': np.float64(0.9867760439713796)}, {'word': ' akcję', 'start': np.float64(14.64), 'end': np.float64(15.04), 'probability': np.float64(0.9540346264839172)}, {'word': ' z', 'start': np.float64(15.04), 'end': np.float64(15.24), 'probability': np.float64(0.3761863708496094)}, {'word': ' możonej', 'start': np.float64(15.24), 'end': np.float64(15.66), 'probability': np.float64(0.7619297727942467)}, {'word': ' kontroli', 'start': np.float64(15.66), 'end': np.float64(16.0), 'probability': np.float64(0.9575576583544413)}, {'word': ' przesyłek', 'start': np.float64(16.0), 'end': np.float64(16.46), 'probability': np.float64(0.932153508067131)}, {'word': ' pocztowych', 'start': np.float64(16.46), 'end': np.float64(16.94), 'probability': np.float64(0.8892597407102585)}, {'word': ' oraz', 'start': np.float64(16.94), 'end': np.float64(17.2), 'probability': np.float64(0.9945045113563538)}, {'word': ' kurierskich.', 'start': np.float64(17.2), 'end': np.float64(17.84), 'probability': np.float64(0.5722627540429434)}]}, {'id': 1, 'seek': 0, 'start': np.float64(18.48), 'end': np.float64(22.1), 'text': ' Funkcjonariusze przeprowadzili kontrolę w 18 punktach w całej Polsce.', 'tokens': [51264, 45285, 45677, 27440, 1381, 30829, 1892, 345, 89, 2312, 14373, 6623, 1274, 261, 2443, 39561, 608, 261, 47631, 73, 35567, 13, 51464], 'temperature': 0.0, 'avg_logprob': -0.1916964572408925, 'compression_ratio': 1.251572327044025, 'no_speech_prob': 0.1463223397731781, 'words': [{'word': ' Funkcjonariusze', 'start': np.float64(18.48), 'end': np.float64(19.14), 'probability': np.float64(0.9015735387802124)}, {'word': ' przeprowadzili', 'start': np.float64(19.14), 'end': np.float64(19.74), 'probability': np.float64(0.9885730385780335)}, {'word': ' kontrolę', 'start': np.float64(19.74), 'end': np.float64(20.28), 'probability': np.float64(\n",
    "    0.9620071450869242)}, {'word': ' w', 'start': np.float64(20.28), 'end': np.float64(20.5), 'probability': np.float64(0.9940767288208008)}, {'word': ' 18', 'start': np.float64(20.5), 'end': np.float64(20.88), 'probability': np.float64(0.8836477994918823)}, {'word': ' punktach', 'start': np.float64(20.88), 'end': np.float64(21.44), 'probability': np.float64(0.9814630448818207)}, {'word': ' w', 'start': np.float64(21.44), 'end': np.float64(21.58), 'probability': np.float64(0.8968337774276733)}, {'word': ' całej', 'start': np.float64(21.58), 'end': np.float64(21.78), 'probability': np.float64(0.845725029706955)}, {'word': ' Polsce.', 'start': np.float64(21.78), 'end': np.float64(22.1), 'probability': np.float64(0.9987391829490662)}]}, {'id': 2, 'seek': 2210, 'start': np.float64(23.92), 'end': np.float64(34.28), 'text': ' Wrześniowa zmiana warunków o prezentowanie obligacji oszczędnościowych wynika z potrzeby ich do stosowania do bieżących realiów rynkowych.', 'tokens': [50414, 10159, 1381, 1788, 3722, 5528, 17020, 8497, 1516, 3197, 3901, 277, 659, 14185, 22028, 9270, 13152, 3003, 43771, 6298, 16438, 19605, 31936, 5439, 710, 28577, 2322, 1893, 360, 43581, 21308, 360, 272, 414, 1427, 1611, 31306, 957, 72, 3901, 367, 2534, 74, 19605, 13, 50964], 'temperature': 0.0, 'avg_logprob': -0.0932230645037712, 'compression_ratio': 1.16, 'no_speech_prob': 0.7557427287101746, 'words': [{'word': ' Wrześniowa', 'start': np.float64(23.92), 'end': np.float64(24.92), 'probability': np.float64(0.903934383392334)}, {'word': ' zmiana', 'start': np.float64(24.92), 'end': np.float64(25.18), 'probability': np.float64(0.9688734412193298)}, {'word': ' warunków', 'start': np.float64(25.18), 'end': np.float64(25.64), 'probability': np.float64(0.8291892608006796)}, {'word': ' o', 'start': np.float64(25.64), 'end': np.float64(25.74), 'probability': np.float64(0.46443796157836914)}, {'word': ' prezentowanie', 'start': np.float64(25.74), 'end': np.float64(26.4), 'probability': np.float64(0.5724625786145529)}, {'word': ' obligacji', 'start': np.float64(26.4), 'end': np.float64(26.94), 'probability': np.float64(0.9240777790546417)}, {'word': ' oszczędnościowych', 'start': np.float64(26.94), 'end': np.float64(27.78), 'probability': np.float64(0.9448558926582337)}, {'word': ' wynika', 'start': np.float64(27.78), 'end': np.float64(28.3), 'probability': np.float64(0.9895245134830475)}, {'word': ' z', 'start': np.float64(28.3), 'end': np.float64(28.66), 'probability': np.float64(0.9921225905418396)}, {'word': ' potrzeby', 'start': np.float64(28.66), 'end': np.float64(30.6), 'probability': np.float64(0.991420179605484)}, {'word': ' ich', 'start': np.float64(30.6), 'end': np.float64(30.94), 'probability': np.float64(0.9871218800544739)}, {'word': ' do', 'start': np.float64(30.94), 'end': np.float64(31.28), 'probability': np.float64(0.9535501003265381)}, {'word': ' stosowania', 'start': np.float64(31.28), 'end': np.float64(31.88), 'probability': np.float64(0.9964969158172607)}, {'word': ' do', 'start': np.float64(31.88), 'end': np.float64(32.18), 'probability': np.float64(0.978425145149231)}, {'word': ' bieżących', 'start': np.float64(32.18), 'end': np.float64(32.98), 'probability': np.float64(0.9854720234870911)}, {'word': ' realiów', 'start': np.float64(32.98), 'end': np.float64(33.8), 'probability': np.float64(0.9118917187054952)}, {'word': ' rynkowych.', 'start': np.float64(33.8), 'end': np.float64(34.28), 'probability': np.float64(0.9939918965101242)}]}], 'language': 'pl'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " W\t11.26\t12.1\n",
      " pierwszej\t12.1\t12.38\n",
      " połowie\t12.38\t12.68\n",
      " lipca\t12.68\t13.06\n",
      " przeprowadziliśmy\t13.06\t13.76\n",
      " ogólnopolską\t13.76\t14.64\n",
      " akcję\t14.64\t15.04\n",
      " z\t15.04\t15.24\n",
      " możonej\t15.24\t15.66\n",
      " kontroli\t15.66\t16.0\n",
      " przesyłek\t16.0\t16.46\n",
      " pocztowych\t16.46\t16.94\n",
      " oraz\t16.94\t17.2\n",
      " kurierskich.\t17.2\t17.84\n",
      " Funkcjonariusze\t18.48\t19.14\n",
      " przeprowadzili\t19.14\t19.74\n",
      " kontrolę\t19.74\t20.28\n",
      " w\t20.28\t20.5\n",
      " 18\t20.5\t20.88\n",
      " punktach\t20.88\t21.44\n",
      " w\t21.44\t21.58\n",
      " całej\t21.58\t21.78\n",
      " Polsce.\t21.78\t22.1\n",
      " Wrześniowa\t23.92\t24.92\n",
      " zmiana\t24.92\t25.18\n",
      " warunków\t25.18\t25.64\n",
      " o\t25.64\t25.74\n",
      " prezentowanie\t25.74\t26.4\n",
      " obligacji\t26.4\t26.94\n",
      " oszczędnościowych\t26.94\t27.78\n",
      " wynika\t27.78\t28.3\n",
      " z\t28.3\t28.66\n",
      " potrzeby\t28.66\t30.6\n",
      " ich\t30.6\t30.94\n",
      " do\t30.94\t31.28\n",
      " stosowania\t31.28\t31.88\n",
      " do\t31.88\t32.18\n",
      " bieżących\t32.18\t32.98\n",
      " realiów\t32.98\t33.8\n",
      " rynkowych.\t33.8\t34.28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(' W', np.float64(11.26), np.float64(12.1)),\n",
       " (' pierwszej', np.float64(12.1), np.float64(12.38)),\n",
       " (' połowie', np.float64(12.38), np.float64(12.68)),\n",
       " (' lipca', np.float64(12.68), np.float64(13.06)),\n",
       " (' przeprowadziliśmy', np.float64(13.06), np.float64(13.76)),\n",
       " (' ogólnopolską', np.float64(13.76), np.float64(14.64)),\n",
       " (' akcję', np.float64(14.64), np.float64(15.04)),\n",
       " (' z', np.float64(15.04), np.float64(15.24)),\n",
       " (' możonej', np.float64(15.24), np.float64(15.66)),\n",
       " (' kontroli', np.float64(15.66), np.float64(16.0)),\n",
       " (' przesyłek', np.float64(16.0), np.float64(16.46)),\n",
       " (' pocztowych', np.float64(16.46), np.float64(16.94)),\n",
       " (' oraz', np.float64(16.94), np.float64(17.2)),\n",
       " (' kurierskich.', np.float64(17.2), np.float64(17.84)),\n",
       " (' Funkcjonariusze', np.float64(18.48), np.float64(19.14)),\n",
       " (' przeprowadzili', np.float64(19.14), np.float64(19.74)),\n",
       " (' kontrolę', np.float64(19.74), np.float64(20.28)),\n",
       " (' w', np.float64(20.28), np.float64(20.5)),\n",
       " (' 18', np.float64(20.5), np.float64(20.88)),\n",
       " (' punktach', np.float64(20.88), np.float64(21.44)),\n",
       " (' w', np.float64(21.44), np.float64(21.58)),\n",
       " (' całej', np.float64(21.58), np.float64(21.78)),\n",
       " (' Polsce.', np.float64(21.78), np.float64(22.1)),\n",
       " (' Wrześniowa', np.float64(23.92), np.float64(24.92)),\n",
       " (' zmiana', np.float64(24.92), np.float64(25.18)),\n",
       " (' warunków', np.float64(25.18), np.float64(25.64)),\n",
       " (' o', np.float64(25.64), np.float64(25.74)),\n",
       " (' prezentowanie', np.float64(25.74), np.float64(26.4)),\n",
       " (' obligacji', np.float64(26.4), np.float64(26.94)),\n",
       " (' oszczędnościowych', np.float64(26.94), np.float64(27.78)),\n",
       " (' wynika', np.float64(27.78), np.float64(28.3)),\n",
       " (' z', np.float64(28.3), np.float64(28.66)),\n",
       " (' potrzeby', np.float64(28.66), np.float64(30.6)),\n",
       " (' ich', np.float64(30.6), np.float64(30.94)),\n",
       " (' do', np.float64(30.94), np.float64(31.28)),\n",
       " (' stosowania', np.float64(31.28), np.float64(31.88)),\n",
       " (' do', np.float64(31.88), np.float64(32.18)),\n",
       " (' bieżących', np.float64(32.18), np.float64(32.98)),\n",
       " (' realiów', np.float64(32.98), np.float64(33.8)),\n",
       " (' rynkowych.', np.float64(33.8), np.float64(34.28))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for segment in DATA[\"segments\"]:\n",
    "    seg_start = segment[\"start\"]\n",
    "    seg_end = segment[\"end\"]\n",
    "    for word in segment[\"words\"]:\n",
    "        word_start = word[\"start\"]\n",
    "        word_end = word[\"end\"]\n",
    "        word_text = word[\"word\"]\n",
    "        print(word_text, word_start, word_end, sep=\"\\t\")\n",
    "        \n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "def get_word_timestamps(data) -> List[Tuple[str, float, float]]:\n",
    "    timestamps = []\n",
    "    for segment in data[\"segments\"]:\n",
    "        for word in segment[\"words\"]:\n",
    "            text = word[\"word\"]\n",
    "            timestamps.append((text, word[\"start\"], word[\"end\"]))\n",
    "    return timestamps\n",
    "\n",
    "get_word_timestamps(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(data) -> str:\n",
    "    return \"\".join(segment[\"text\"] for segment in data[\"segments\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = get_text(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.333333333333336\n",
      "college_graduate\n"
     ]
    }
   ],
   "source": [
    "from readability import Readability\n",
    "\n",
    "\n",
    "def duplicate_sample(sample: str):\n",
    "    \"\"\"\n",
    "    Output sample must have more than 100 words.\n",
    "    \"\"\"\n",
    "    no_words = len(sample.split())\n",
    "    no_words_expected = 100\n",
    "    multiply = (no_words_expected // no_words + 1) \n",
    "    return sample * multiply\n",
    "\n",
    "t = duplicate_sample(TEXT)\n",
    "r = Readability(t)\n",
    "gf = r.gunning_fog()\n",
    "print(gf.score)\n",
    "print(gf.grade_level)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 17\tCollege graduate\n",
    "# 16\tCollege senior\n",
    "# 15\tCollege junior\n",
    "# 14\tCollege sophomore\n",
    "# 13\tCollege freshman\n",
    "# 12\tHigh school senior\n",
    "# 11\tHigh school junior\n",
    "# 10\tHigh school sophomore\n",
    "# 9\tHigh school freshman\n",
    "# 8\tEighth grade\n",
    "# 7\tSeventh grade\n",
    "# 6\tSixth grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/szymon/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' W pierwszej połowie lipca przeprowadziliśmy ogólnopolską akcję z możonej kontroli przesyłek pocztowych oraz kurierskich. Funkcjonariusze przeprowadzili kontrolę w 18 punktach w całej Polsce. Wrześniowa zmiana warunków o prezentowanie obligacji oszczędnościowych wynika z potrzeby ich do stosowania do bieżących realiów rynkowych.',\n",
       " 'segments': [{'id': 0,\n",
       "   'seek': 0,\n",
       "   'start': np.float64(11.26),\n",
       "   'end': np.float64(17.84),\n",
       "   'text': ' W pierwszej połowie lipca przeprowadziliśmy ogólnopolską akcję z możonej kontroli przesyłek pocztowych oraz kurierskich.',\n",
       "   'tokens': [50364,\n",
       "    343,\n",
       "    27623,\n",
       "    16920,\n",
       "    714,\n",
       "    1221,\n",
       "    13998,\n",
       "    8280,\n",
       "    496,\n",
       "    30829,\n",
       "    1892,\n",
       "    345,\n",
       "    89,\n",
       "    43912,\n",
       "    5360,\n",
       "    15741,\n",
       "    77,\n",
       "    19946,\n",
       "    5161,\n",
       "    1611,\n",
       "    9308,\n",
       "    41960,\n",
       "    710,\n",
       "    705,\n",
       "    1427,\n",
       "    546,\n",
       "    73,\n",
       "    14373,\n",
       "    340,\n",
       "    2081,\n",
       "    6541,\n",
       "    17823,\n",
       "    1221,\n",
       "    916,\n",
       "    714,\n",
       "    66,\n",
       "    2682,\n",
       "    19605,\n",
       "    28905,\n",
       "    10072,\n",
       "    4890,\n",
       "    48349,\n",
       "    13,\n",
       "    51264],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1916964572408925,\n",
       "   'compression_ratio': 1.251572327044025,\n",
       "   'no_speech_prob': 0.1463223397731781,\n",
       "   'words': [{'word': ' W',\n",
       "     'start': np.float64(11.26),\n",
       "     'end': np.float64(12.1),\n",
       "     'probability': np.float64(0.5698226094245911)},\n",
       "    {'word': ' pierwszej',\n",
       "     'start': np.float64(12.1),\n",
       "     'end': np.float64(12.38),\n",
       "     'probability': np.float64(0.9487821459770203)},\n",
       "    {'word': ' połowie',\n",
       "     'start': np.float64(12.38),\n",
       "     'end': np.float64(12.68),\n",
       "     'probability': np.float64(0.9906543095906576)},\n",
       "    {'word': ' lipca',\n",
       "     'start': np.float64(12.68),\n",
       "     'end': np.float64(13.06),\n",
       "     'probability': np.float64(0.9368249475955963)},\n",
       "    {'word': ' przeprowadziliśmy',\n",
       "     'start': np.float64(13.06),\n",
       "     'end': np.float64(13.76),\n",
       "     'probability': np.float64(0.9441170692443848)},\n",
       "    {'word': ' ogólnopolską',\n",
       "     'start': np.float64(13.76),\n",
       "     'end': np.float64(14.64),\n",
       "     'probability': np.float64(0.9867760439713796)},\n",
       "    {'word': ' akcję',\n",
       "     'start': np.float64(14.64),\n",
       "     'end': np.float64(15.04),\n",
       "     'probability': np.float64(0.9540346264839172)},\n",
       "    {'word': ' z',\n",
       "     'start': np.float64(15.04),\n",
       "     'end': np.float64(15.24),\n",
       "     'probability': np.float64(0.3761863708496094)},\n",
       "    {'word': ' możonej',\n",
       "     'start': np.float64(15.24),\n",
       "     'end': np.float64(15.66),\n",
       "     'probability': np.float64(0.7619297727942467)},\n",
       "    {'word': ' kontroli',\n",
       "     'start': np.float64(15.66),\n",
       "     'end': np.float64(16.0),\n",
       "     'probability': np.float64(0.9575576583544413)},\n",
       "    {'word': ' przesyłek',\n",
       "     'start': np.float64(16.0),\n",
       "     'end': np.float64(16.46),\n",
       "     'probability': np.float64(0.932153508067131)},\n",
       "    {'word': ' pocztowych',\n",
       "     'start': np.float64(16.46),\n",
       "     'end': np.float64(16.94),\n",
       "     'probability': np.float64(0.8892597407102585)},\n",
       "    {'word': ' oraz',\n",
       "     'start': np.float64(16.94),\n",
       "     'end': np.float64(17.2),\n",
       "     'probability': np.float64(0.9945045113563538)},\n",
       "    {'word': ' kurierskich.',\n",
       "     'start': np.float64(17.2),\n",
       "     'end': np.float64(17.84),\n",
       "     'probability': np.float64(0.5722627540429434)}]},\n",
       "  {'id': 1,\n",
       "   'seek': 0,\n",
       "   'start': np.float64(18.48),\n",
       "   'end': np.float64(22.1),\n",
       "   'text': ' Funkcjonariusze przeprowadzili kontrolę w 18 punktach w całej Polsce.',\n",
       "   'tokens': [51264,\n",
       "    45285,\n",
       "    45677,\n",
       "    27440,\n",
       "    1381,\n",
       "    30829,\n",
       "    1892,\n",
       "    345,\n",
       "    89,\n",
       "    2312,\n",
       "    14373,\n",
       "    6623,\n",
       "    1274,\n",
       "    261,\n",
       "    2443,\n",
       "    39561,\n",
       "    608,\n",
       "    261,\n",
       "    47631,\n",
       "    73,\n",
       "    35567,\n",
       "    13,\n",
       "    51464],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.1916964572408925,\n",
       "   'compression_ratio': 1.251572327044025,\n",
       "   'no_speech_prob': 0.1463223397731781,\n",
       "   'words': [{'word': ' Funkcjonariusze',\n",
       "     'start': np.float64(18.48),\n",
       "     'end': np.float64(19.14),\n",
       "     'probability': np.float64(0.9015735387802124)},\n",
       "    {'word': ' przeprowadzili',\n",
       "     'start': np.float64(19.14),\n",
       "     'end': np.float64(19.74),\n",
       "     'probability': np.float64(0.9885730385780335)},\n",
       "    {'word': ' kontrolę',\n",
       "     'start': np.float64(19.74),\n",
       "     'end': np.float64(20.28),\n",
       "     'probability': np.float64(0.9620071450869242)},\n",
       "    {'word': ' w',\n",
       "     'start': np.float64(20.28),\n",
       "     'end': np.float64(20.5),\n",
       "     'probability': np.float64(0.9940767288208008)},\n",
       "    {'word': ' 18',\n",
       "     'start': np.float64(20.5),\n",
       "     'end': np.float64(20.88),\n",
       "     'probability': np.float64(0.8836477994918823)},\n",
       "    {'word': ' punktach',\n",
       "     'start': np.float64(20.88),\n",
       "     'end': np.float64(21.44),\n",
       "     'probability': np.float64(0.9814630448818207)},\n",
       "    {'word': ' w',\n",
       "     'start': np.float64(21.44),\n",
       "     'end': np.float64(21.58),\n",
       "     'probability': np.float64(0.8968337774276733)},\n",
       "    {'word': ' całej',\n",
       "     'start': np.float64(21.58),\n",
       "     'end': np.float64(21.78),\n",
       "     'probability': np.float64(0.845725029706955)},\n",
       "    {'word': ' Polsce.',\n",
       "     'start': np.float64(21.78),\n",
       "     'end': np.float64(22.1),\n",
       "     'probability': np.float64(0.9987391829490662)}]},\n",
       "  {'id': 2,\n",
       "   'seek': 2210,\n",
       "   'start': np.float64(23.92),\n",
       "   'end': np.float64(34.28),\n",
       "   'text': ' Wrześniowa zmiana warunków o prezentowanie obligacji oszczędnościowych wynika z potrzeby ich do stosowania do bieżących realiów rynkowych.',\n",
       "   'tokens': [50414,\n",
       "    10159,\n",
       "    1381,\n",
       "    1788,\n",
       "    3722,\n",
       "    5528,\n",
       "    17020,\n",
       "    8497,\n",
       "    1516,\n",
       "    3197,\n",
       "    3901,\n",
       "    277,\n",
       "    659,\n",
       "    14185,\n",
       "    22028,\n",
       "    9270,\n",
       "    13152,\n",
       "    3003,\n",
       "    43771,\n",
       "    6298,\n",
       "    16438,\n",
       "    19605,\n",
       "    31936,\n",
       "    5439,\n",
       "    710,\n",
       "    28577,\n",
       "    2322,\n",
       "    1893,\n",
       "    360,\n",
       "    43581,\n",
       "    21308,\n",
       "    360,\n",
       "    272,\n",
       "    414,\n",
       "    1427,\n",
       "    1611,\n",
       "    31306,\n",
       "    957,\n",
       "    72,\n",
       "    3901,\n",
       "    367,\n",
       "    2534,\n",
       "    74,\n",
       "    19605,\n",
       "    13,\n",
       "    50964],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.0932230645037712,\n",
       "   'compression_ratio': 1.16,\n",
       "   'no_speech_prob': 0.7557427287101746,\n",
       "   'words': [{'word': ' Wrześniowa',\n",
       "     'start': np.float64(23.92),\n",
       "     'end': np.float64(24.92),\n",
       "     'probability': np.float64(0.903934383392334)},\n",
       "    {'word': ' zmiana',\n",
       "     'start': np.float64(24.92),\n",
       "     'end': np.float64(25.18),\n",
       "     'probability': np.float64(0.9688734412193298)},\n",
       "    {'word': ' warunków',\n",
       "     'start': np.float64(25.18),\n",
       "     'end': np.float64(25.64),\n",
       "     'probability': np.float64(0.8291892608006796)},\n",
       "    {'word': ' o',\n",
       "     'start': np.float64(25.64),\n",
       "     'end': np.float64(25.74),\n",
       "     'probability': np.float64(0.46443796157836914)},\n",
       "    {'word': ' prezentowanie',\n",
       "     'start': np.float64(25.74),\n",
       "     'end': np.float64(26.4),\n",
       "     'probability': np.float64(0.5724625786145529)},\n",
       "    {'word': ' obligacji',\n",
       "     'start': np.float64(26.4),\n",
       "     'end': np.float64(26.94),\n",
       "     'probability': np.float64(0.9240777790546417)},\n",
       "    {'word': ' oszczędnościowych',\n",
       "     'start': np.float64(26.94),\n",
       "     'end': np.float64(27.78),\n",
       "     'probability': np.float64(0.9448558926582337)},\n",
       "    {'word': ' wynika',\n",
       "     'start': np.float64(27.78),\n",
       "     'end': np.float64(28.3),\n",
       "     'probability': np.float64(0.9895245134830475)},\n",
       "    {'word': ' z',\n",
       "     'start': np.float64(28.3),\n",
       "     'end': np.float64(28.66),\n",
       "     'probability': np.float64(0.9921225905418396)},\n",
       "    {'word': ' potrzeby',\n",
       "     'start': np.float64(28.66),\n",
       "     'end': np.float64(30.6),\n",
       "     'probability': np.float64(0.991420179605484)},\n",
       "    {'word': ' ich',\n",
       "     'start': np.float64(30.6),\n",
       "     'end': np.float64(30.94),\n",
       "     'probability': np.float64(0.9871218800544739)},\n",
       "    {'word': ' do',\n",
       "     'start': np.float64(30.94),\n",
       "     'end': np.float64(31.28),\n",
       "     'probability': np.float64(0.9535501003265381)},\n",
       "    {'word': ' stosowania',\n",
       "     'start': np.float64(31.28),\n",
       "     'end': np.float64(31.88),\n",
       "     'probability': np.float64(0.9964969158172607)},\n",
       "    {'word': ' do',\n",
       "     'start': np.float64(31.88),\n",
       "     'end': np.float64(32.18),\n",
       "     'probability': np.float64(0.978425145149231)},\n",
       "    {'word': ' bieżących',\n",
       "     'start': np.float64(32.18),\n",
       "     'end': np.float64(32.98),\n",
       "     'probability': np.float64(0.9854720234870911)},\n",
       "    {'word': ' realiów',\n",
       "     'start': np.float64(32.98),\n",
       "     'end': np.float64(33.8),\n",
       "     'probability': np.float64(0.9118917187054952)},\n",
       "    {'word': ' rynkowych.',\n",
       "     'start': np.float64(33.8),\n",
       "     'end': np.float64(34.28),\n",
       "     'probability': np.float64(0.9939918965101242)}]}],\n",
       " 'language': 'pl'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../odm.txt\") as f:\n",
    "    odm = f.read()\n",
    "    odm = [word.lower().replace(\",\", \"\").strip() for word in odm.split() if len(word) > 4 and word[0] == \"p\"]\n",
    "    with open(\"out.txt\", \"w\") as ff:\n",
    "        ff.write(\"\\n\".join(odm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./slowa.txt\") as f:\n",
    "    odm = f.read()\n",
    "    odm = [word.strip() for word in odm.split()]\n",
    "\n",
    "\"odważyła\" in odm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../words2.txt\") as f:\n",
    "    a = [w for w in f.read().lower().splitlines() if len(w) > 5]\n",
    "a.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search(arr, target):\n",
    "    low = 0\n",
    "    high = len(arr) - 1\n",
    "\n",
    "    while low <= high:\n",
    "        mid = (low + high) // 2\n",
    "\n",
    "        # Check if the target is at mid\n",
    "        if arr[mid] == target:\n",
    "            return mid\n",
    "        # If target is smaller than mid, ignore the right half\n",
    "        elif arr[mid] > target:\n",
    "            high = mid - 1\n",
    "        # If target is greater than mid, ignore the left half\n",
    "        else:\n",
    "            low = mid + 1\n",
    "\n",
    "    # If the target is not present in the array\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_search(a, \"robić\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hy_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
